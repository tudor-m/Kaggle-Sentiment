{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50bc29d151fa6192be326cbc343ce0b6e40405b4"
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm --user\n",
    "!pip install kaggle --user\n",
    "!pip install kaggle.competitions --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import lightgbm as lgb\n",
    "import pandas as pd\n",
    "#from kaggle.competitions import twosigmanews\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from datetime import datetime, date\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "2a60d768ec157469fe0512b86356dace3c41233a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "env = twosigmanews.make_env()\n",
       "\n",
       "(market_train_df, news_train_df) = env.get_training_data()\n",
       "market_train, news_train = market_train_df.copy(), news_train_df.copy()"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "env = twosigmanews.make_env()\n",
    "\n",
    "(market_train_df, news_train_df) = env.get_training_data()\n",
    "market_train, news_train = market_train_df.copy(), news_train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_train, news_train = pd.read_csv(\"../input/marketdata_sample.csv\"),pd.read_csv(\"../input/news_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "18e28d137095d5b88b02accba9e190f2f07bf165"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>sourceTimestamp</th>\n",
       "      <th>firstCreated</th>\n",
       "      <th>sourceId</th>\n",
       "      <th>headline</th>\n",
       "      <th>urgency</th>\n",
       "      <th>takeSequence</th>\n",
       "      <th>provider</th>\n",
       "      <th>subjects</th>\n",
       "      <th>audiences</th>\n",
       "      <th>...</th>\n",
       "      <th>noveltyCount12H</th>\n",
       "      <th>noveltyCount24H</th>\n",
       "      <th>noveltyCount3D</th>\n",
       "      <th>noveltyCount5D</th>\n",
       "      <th>noveltyCount7D</th>\n",
       "      <th>volumeCounts12H</th>\n",
       "      <th>volumeCounts24H</th>\n",
       "      <th>volumeCounts3D</th>\n",
       "      <th>volumeCounts5D</th>\n",
       "      <th>volumeCounts7D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01 04:29:32+00:00</td>\n",
       "      <td>2007-01-01 04:29:32+00:00</td>\n",
       "      <td>2007-01-01 04:29:32+00:00</td>\n",
       "      <td>e58c6279551b85cf</td>\n",
       "      <td>China's Daqing pumps 43.41 mln tonnes of oil i...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'CRU', 'CN', 'RTRS', 'ENR', 'LEN', 'EMRG', 'N...</td>\n",
       "      <td>{'O', 'Z', 'OIL'}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-01 07:03:35+00:00</td>\n",
       "      <td>2007-01-01 07:03:34+00:00</td>\n",
       "      <td>2007-01-01 07:03:34+00:00</td>\n",
       "      <td>5a31c4327427f63f</td>\n",
       "      <td>FEATURE-In kidnapping, finesse works best</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'BD', 'INS', 'LATAM', 'CA', 'US', 'MX', 'IL',...</td>\n",
       "      <td>{'PGE', 'PCU', 'PCO', 'DNP', 'MD', 'E', 'G', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time            sourceTimestamp  \\\n",
       "0  2007-01-01 04:29:32+00:00  2007-01-01 04:29:32+00:00   \n",
       "1  2007-01-01 07:03:35+00:00  2007-01-01 07:03:34+00:00   \n",
       "\n",
       "                firstCreated          sourceId  \\\n",
       "0  2007-01-01 04:29:32+00:00  e58c6279551b85cf   \n",
       "1  2007-01-01 07:03:34+00:00  5a31c4327427f63f   \n",
       "\n",
       "                                            headline  urgency  takeSequence  \\\n",
       "0  China's Daqing pumps 43.41 mln tonnes of oil i...        3             1   \n",
       "1          FEATURE-In kidnapping, finesse works best        3             1   \n",
       "\n",
       "  provider                                           subjects  \\\n",
       "0     RTRS  {'CRU', 'CN', 'RTRS', 'ENR', 'LEN', 'EMRG', 'N...   \n",
       "1     RTRS  {'BD', 'INS', 'LATAM', 'CA', 'US', 'MX', 'IL',...   \n",
       "\n",
       "                                           audiences       ...        \\\n",
       "0                                  {'O', 'Z', 'OIL'}       ...         \n",
       "1  {'PGE', 'PCU', 'PCO', 'DNP', 'MD', 'E', 'G', '...       ...         \n",
       "\n",
       "   noveltyCount12H  noveltyCount24H noveltyCount3D  noveltyCount5D  \\\n",
       "0                0                0              0               0   \n",
       "1                1                1              1               1   \n",
       "\n",
       "   noveltyCount7D  volumeCounts12H volumeCounts24H volumeCounts3D  \\\n",
       "0               0                0               0              3   \n",
       "1               1                1               1              3   \n",
       "\n",
       "   volumeCounts5D  volumeCounts7D  \n",
       "0               6               7  \n",
       "1               3               3  \n",
       "\n",
       "[2 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "51d904e9fd57dc968c9808e0f86c43d553afc5ed"
   },
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4856c0a87ba664a6040bcda5b90caa15006b4b1"
   },
   "outputs": [],
   "source": [
    "def mis_impute(data):\n",
    "    for i in data.columns:\n",
    "        if data[i].dtype == \"object\":\n",
    "            data[i] = data[i].fillna(\"other\")\n",
    "        elif (data[i].dtype == \"int64\" or data[i].dtype == \"float64\"):\n",
    "            data[i] = data[i].fillna(data[i].mean())\n",
    "        else:\n",
    "            pass\n",
    "    return data\n",
    "\n",
    "market_train_df = mis_impute(market_train_df)\n",
    "\n",
    "def data_prep(market_train):\n",
    "    market_train.time = market_train.time.dt.date\n",
    "    lbl = {k: v for v, k in enumerate(market_train['assetCode'].unique())}\n",
    "    market_train['assetCodeT'] = market_train['assetCode'].map(lbl)\n",
    "    \n",
    "    market_train = market_train.dropna(axis=0)\n",
    "    \n",
    "    return market_train\n",
    "\n",
    "market_train = data_prep(market_train_df)\n",
    "\n",
    "# check the shape\n",
    "print(market_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "886507a9c0384f0919b922b5ff8e2764c9575e0c"
   },
   "outputs": [],
   "source": [
    "market_train = market_train.loc[market_train['time']>=date(2009, 1, 1)]\n",
    "up = market_train.returnsOpenNextMktres10 >= 0\n",
    "fcol = [c for c in market_train if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'audiences', \n",
    "                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'provider', \n",
    "                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'time_x', 'universe','sourceTimestamp']]\n",
    "\n",
    "X = market_train[fcol].values\n",
    "up = up.values\n",
    "r = market_train.returnsOpenNextMktres10.values\n",
    "\n",
    "# Scaling of X values\n",
    "# It is good to keep these scaling values for later\n",
    "mins = np.min(X, axis=0)\n",
    "maxs = np.max(X, axis=0)\n",
    "rng = maxs - mins\n",
    "X = 1 - ((maxs - X) / rng)\n",
    "\n",
    "# Sanity check\n",
    "assert X.shape[0] == up.shape[0] == r.shape[0]\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "X_train, X_test, up_train, up_test, r_train, r_test = model_selection.train_test_split(X, up, r, test_size=0.25, random_state=99)\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=up_train.astype(int))\n",
    "test_data = lgb.Dataset(X_test, label=up_test.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d49a70d9691361dcd2e06513fe44e83604f03ec2"
   },
   "source": [
    "# Tuning hyper-params with skopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "647493abe54d31de0e8662a46c51ff6f800d11e5"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# use this section if you want to customize optimization\n",
    "\n",
    "# define blackbox function\n",
    "def f(x):\n",
    "    print(x)\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'dart',\n",
    "        'objective': 'binary',\n",
    "        'learning_rate': x[0],\n",
    "        'num_leaves': x[1],\n",
    "        'min_data_in_leaf': x[2],\n",
    "        'num_iteration': x[3],\n",
    "        'max_bin': x[4],\n",
    "        'verbose': 1\n",
    "    }\n",
    "    \n",
    "    gbm = lgb.train(params,\n",
    "            train_data,\n",
    "            num_boost_round=100,\n",
    "            valid_sets=test_data,\n",
    "            early_stopping_rounds=5)\n",
    "            \n",
    "    print(type(gbm.predict(X_test, num_iteration=gbm.best_iteration)[0]),type(up_test.astype(int)[0]))\n",
    "    \n",
    "    print('score: ', mean_squared_error(gbm.predict(X_test, num_iteration=gbm.best_iteration), up_test.astype(float)))\n",
    "    \n",
    "    return mean_squared_error(gbm.predict(X_test, num_iteration=gbm.best_iteration), up_test.astype(float))\n",
    "\n",
    "# optimize params in these ranges\n",
    "spaces = [\n",
    "    (0.19, 0.20), #learning_rate\n",
    "    (2450, 2600), #num_leaves\n",
    "    (210, 230), #min_data_in_leaf\n",
    "    (310, 330), #num_iteration\n",
    "    (200, 220) #max_bin\n",
    "    ]\n",
    "\n",
    "# run optimization\n",
    "from skopt import gp_minimize\n",
    "res = gp_minimize(\n",
    "    f, spaces,\n",
    "    acq_func=\"EI\",\n",
    "    n_calls=10) # increase n_calls for more performance\n",
    "\n",
    "# print tuned params\n",
    "print(res.x)\n",
    "\n",
    "# plot tuning process\n",
    "from skopt.plots import plot_convergence\n",
    "plot_convergence(res)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "45c99e6b4fb86f54d020723d13031a923c8d3808"
   },
   "source": [
    "# Training with tuned params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6ac689319157951828d4e4a713ae688ea5e618c"
   },
   "outputs": [],
   "source": [
    "# these are tuned params I found\n",
    "x_1 = [0.19000424246380565, 2452, 212, 328, 202]\n",
    "x_2 = [0.19016805202090095, 2583, 213, 312, 220]\n",
    "\n",
    "params_1 = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'dart',\n",
    "        'objective': 'binary',\n",
    "        'learning_rate': x_1[0],\n",
    "        'num_leaves': x_1[1],\n",
    "        'min_data_in_leaf': x_1[2],\n",
    "        'num_iteration': x_1[3],\n",
    "        'max_bin': x_1[4],\n",
    "        'verbose': 1\n",
    "    }\n",
    "\n",
    "params_2 = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'dart',\n",
    "        'objective': 'binary',\n",
    "        'learning_rate': x_2[0],\n",
    "        'num_leaves': x_2[1],\n",
    "        'min_data_in_leaf': x_2[2],\n",
    "        'num_iteration': x_2[3],\n",
    "        'max_bin': x_2[4],\n",
    "        'verbose': 1\n",
    "    }\n",
    "\n",
    "\n",
    "gbm_1 = lgb.train(params_1,\n",
    "        train_data,\n",
    "        num_boost_round=100,\n",
    "        valid_sets=test_data,\n",
    "        early_stopping_rounds=5)\n",
    "        \n",
    "gbm_2 = lgb.train(params_2,\n",
    "        train_data,\n",
    "        num_boost_round=100,\n",
    "        valid_sets=test_data,\n",
    "        early_stopping_rounds=5)\n",
    "        \n",
    "\n",
    "#prediction\n",
    "days = env.get_prediction_days()\n",
    "n_days = 0\n",
    "prep_time = 0\n",
    "prediction_time = 0\n",
    "packaging_time = 0\n",
    "for (market_obs_df, news_obs_df, predictions_template_df) in days:\n",
    "    n_days +=1\n",
    "    if (n_days%50==0):\n",
    "        print(n_days,end=' ')\n",
    "    t = time.time()\n",
    "    market_obs_df = data_prep(market_obs_df)\n",
    "    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n",
    "    X_live = market_obs_df[fcol].values\n",
    "    X_live = 1 - ((maxs - X_live) / rng)\n",
    "    prep_time += time.time() - t\n",
    "    \n",
    "    t = time.time()\n",
    "    lp = (gbm_1.predict(X_live) + gbm_2.predict(X_live))/2\n",
    "    prediction_time += time.time() -t\n",
    "    \n",
    "    t = time.time()\n",
    "\n",
    "    confidence = lp\n",
    "    confidence = (confidence-confidence.min())/(confidence.max()-confidence.min())\n",
    "    confidence = confidence * 2 - 1\n",
    "    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n",
    "    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n",
    "    env.predict(predictions_template_df)\n",
    "    packaging_time += time.time() - t\n",
    "    \n",
    "env.write_submission_file()\n",
    "sub  = pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7376622bed44ed4f009c47ed1d5acf177720f857"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
